[["index.html", "R Tools for Quantitative Data Analysis Introduction", " R Tools for Quantitative Data Analysis Nick Garvin 2022-07-25 Introduction This manual provides the building blocks for using R for data analysis. When combined in the right ways, these tools can do pretty much anything you can imagine that involves manipulating or modelling data. There are lots of chunks of example code. Copy and paste and run them yourself. They include useful demonstrations, as well as many handy and commonly-used functions that you can borrow for your own code. Everything before section 5 is about tools in base R (i.e. R without any extra packages installed). Base R is worth understanding well no matter what packages you end up using, because base R has more flexibility than package alternatives. Section 5 briefly covers two particularly useful packages – data.table and magrittr. These are used in section 6 on graphs, which also briefly covers the ggplot2 graphing package. Another great resource for learning R is Hadley Wickham’s ‘Advanced R’ book (free at https://adv-r.hadley.nz/index.html), and various other Tidyverse resources. The main differences from this manual are: This manual has more emphasis on working with quantitative data, and less on other R topics related to package development and programming more generally. Advanced R assumes use of Hadley Wickham’s Tidyverse set of packages. Many people prefer other approaches (discussed in section 5.5). This manual is relevant whether you’re using Tidyverse packages or not. What this manual covers Getting started discusses: how to set up R, RStudio and R packages; some key concepts used in a typical line of R code; and how to write code neatly. It finishes with a block of example code that you can run to get some familiarity. Types of data objects discusses the features of the main types of data objects that your code will use, and how to use them. If, instead, you want to dive straight in and learn by doing, you can go straight to chapter 3. Sourcing data discusses some common functions for reading datasets into R, and how to use RStudio projects. Functions provides more detail on how to use and understand R’s functions, and how to write your own functions. It also discusses environments, which are basically the structures in which R stores objects. Understanding environments is helpful for being able to write reliable functions. The data.table and magrittr packages discusses two particularly useful packages for working with data. I use both of these in almost all my R coding. Graphs provides example code for creating various types of graphs. You can use this code as a starting point for making your own graphs. "],["getting-started.html", "Chapter 1 Getting started 1.1 RStudio 1.2 Base R and installing packages 1.3 What is a line of R code? 1.4 Coding style 1.5 Example code to play with", " Chapter 1 Getting started There are two places to write R code: The R console. This is where code is run. If you write directly into the console, each time you hit enter it will run what you wrote. If you open R without RStudio, R will just show the console. Try it. Scripts. An R script is basically a text file (but, if using RStudio, with a .R extension). This is where code is saved. You send whole scripts or bits of them to the console for execution. Use RStudio, which makes writing, running and saving scripts easy. Although R is open source, RStudio is commercial software, but the standard version is free of charge, and if it doesn’t stay that way someone will hopefully develop an open-source alternative. Some small parts of this document are specific to using R in RStudio. 1.1 RStudio To get started with RStudio: Download and install R and RStudio (for windows, from here https://cran.rstudio.com/ and here https://www.rstudio.com/products/rstudio/download/#download), and open RStudio. Click “File”, then “New file”, then “R Script”. Write code into the script. Run code by highlighting it and typing ctrl + enter, or run a line by hitting ctrl + enter when your cursor is on that line, or run the whole script down to your cursor by typing ctrl + alt + b. Save the script if you want to keep it. TIP: save your R scripts, not your R ‘sessions’. (The session is the collection of data objects your script has created.) It’s better to recreate the session by running your saved script than to open a pre-saved session. Then you’ll have the R objects you need and a record of how they were created and the ability to reproduce them. TIP: regularly run your whole script, to check everything still works. Before each re-run, clear your session to make sure it’s starting fresh. You can clear your session by typing ctr + shift + F10, but RStudio first needs to have some settings adjusted. This is common practice and needs to be done due to legacy issues. Click “Tools, then”Global Options”. In “R General” and “Basic”, under “Workspace”, make sure “Restore .RData into workspace at startup” is unticked, and “Save workspace to .RData on exit:” is set to “Never”. Click “Apply”. Other commonly used RStudio functionality: RStudio projects are very useful for grouping files that belong to the same piece of work, such as scripts that relate to each other, input files read by the script/s (e.g. datasets stored locally), and outputs. It’s good habit to always do your work in an RStudio project. These are discussed in section 3.3 R Markdown is great for presenting code/output/text to someone that will be more interested in reading the content than running the code themselves. For example, this document was produced in R Markdown. But only use it for these purposes – it wasn’t intended to be used for general coding, which standard scripts are better for. 1.2 Base R and installing packages Base R refers to R without any additional packages installed, which is what you get when you first install R. This document focuses mostly on base R, which can do a vast range of things. Packages build on base R to add functionality, but rarely do anything related to data manipulation that cannot be done in base R. Rather, they’re usually intended to make doing that thing significantly easier, by reducing the amount of code required or making the operations faster. To use a package: Install it on your computer by running install.packages('&lt;package name&gt;') in the console, for example install.packages('data.table'). This only needs to be done once. Load it each time you open a new R session, by running library(&lt;package name&gt;), for example library(data.table). Write it into the top of the script, for visibility. This brings its functions into your ‘namespace’ environment and makes them available to call. Alternatively, you can call a function from a package that is installed but not loaded, by typing the package name with ::. For example, data.table::melt() calls the melt() function without data.table needing to be loaded. This avoids bringing the package’s functions into the namespace environment and can help prevent function-name duplication. Careful: Using additional packages does some bring costs, like package dependencies, potential function-name duplication, and small overheads. Don’t let that stop you. Just do this: only start relying on an additional package if it provides a noticeable benefit over what you have already. Also, if your code is running critical processes, make sure you’re managing these risks. A few widely used packages can change how the R syntax looks, so if after reading sections 1 and 2, you see R code that still looks foreign to you, this is probably the reason. Section 5 covers that. 1.3 What is a line of R code? These are things worth knowing before you start: R is case sensitive. R uses sequential execution. R runs code one line at a time. The results of one line are produced, and ready to use, before the next line is run. Lines are separated by typing enter. Splitting lines: R reads multiple lines as one if the first line(s) have an unfinished operation, such as ( without ), or + with nothing afterward until the next line. Pipes: The ‘pipe’ operator %&gt;%, from the magrittr package, slightly modifies the concept of ‘a line of R code’. This is discussed in section 5. Assignment (&lt;-): Most lines of R code are an assignment, to create or modify a data object. Assignment can create a new object. For example, y &lt;- 3 creates a new object called y, containing 3. The assignment operator &lt;- gives the RHS data object (e.g. 3) the name (AKA symbol) on the LHS (e.g. y), and stores it in your session’s ‘environment’. If an object of that name already existed, it is over-written. Have the ‘Environment’ pane in RStudio open when you run an assignment, and you will see the object appear when it is assigned. Assignment can also modify an existing object. To do this, instead or having just an object name to the left of &lt;-, ‘index’ an existing object to refer to a specific component of it. Indexing is discussed more shortly. The operation on the right of &lt;- is done before the name is assigned. So, for example, x &lt;- x + 1 does not cause a contradiction; it uses the pre-existing x on the right then creates the new x on the left. Object names: names can be any text without spaces, but cannot start with numbers. Most people use underscores instead of spaces. Some old dogs use a dot. Operations: an operation can be run without an assignment, which will usually just display the result of that operation in the console. Comments: R ignores any line that starts with #, regardless of what is after it. If # appears partway through a line, everything after the # is ignored. Error messages: When the console shows a message starting with ‘Error’, the piece of code that produced that message did not run. When the message starts with ‘Warning’, the code did run, but something unintended may have happened. The information in this manual should help you to understand the language used in these messages. 1.4 Coding style Make your code easily readable, for your later self and for others. Some tips: Keep each line of your script within 90 characters. Nobody likes having to scroll left and right to look at code. Achieve this by splitting your lines as mentioned in section 1.3. Some use 80 characters. Liberally comment your code. It’s also usually better to describe what you’re doing, rather than how you’re doing it. When the reader knows the ‘what’, they can usually get the ‘how’ from the code. Follow a style guide, such as Hadley Wickham’s (http://adv-r.had.co.nz/Style.html) or whatever you find and like. The important thing is that your code is readable, which this will help with. Spend time cleaning your code, after you’ve first got it working, if the code is worth keeping. Code is clean when it achieves its purpose in close to as few steps as possible, and is neatly laid and out and commented. If your code isn’t clean, it’s reasonably likely to have mistakes that haven’t been noticed. 1.5 Example code to play with ### Generate some mock variables and run a simple regression on them. # Set your desired sample size samp_size &lt;- 1000 # Set the regression parameters alpha &lt;- 0.75 beta &lt;- 2 # Create an x variable vector, as a sequence from 1 to the sample size x &lt;- seq(1, samp_size) # Do the same thing another way (the operator &#39;:&#39; creates a sequence of integers) x2 &lt;- 1:samp_size # Show that they&#39;re the same (an example of operation without assignment). identical(x, x2) # Remove the unneeded one. rm(x2) # Generate the regression residuals by randomly selecting from a normal distribution e &lt;- rnorm(n=samp_size) # Show the chosen parameters alpha beta # Show the x variables and residuals. Just look at the first few values. head(x) # alternatively the tail() function shows the last few values. head(e) # Generate the left-hand-side y variable from the components already specified. # The assignment is unnecessarily split over two lines, for illustration. y &lt;- alpha + (beta * x) + e # Regress the y variable on the x variable. lm() is the standard function for regression. reg_output &lt;- lm(y ~ x) # Report the output from regression reg_output summary(reg_output) ### Exercise for the interested: # - Rerun the code a bunch of times, changing the sample size (e.g. 10, 100, 10 000, etc). # (Even with the same sample size the results will change, because rnorm gives different # values each time.) # - See if you notice a pattern between the sample size, and how close your specified # alpha and beta parameters are to the regression coefficients. # - This pattern is a &#39;law of large numbers&#39; at work. "],["object-types.html", "Chapter 2 Types of data objects 2.1 Vectors 2.2 Vector operations and indexing 2.3 Arrays 2.4 Data frames 2.5 Lists 2.6 ‘If’ statements and ‘for’ loops 2.7 Recap", " Chapter 2 Types of data objects Objects are pieces of data that are named and stored in the R session (AKA environment), ready for your code to call upon. Indexing is an essential operation that involves extracting a piece of a data object. Indexing is also used to modify objects, by assigning something to the indexed part of the object. Functions do things to data (and other) objects. Most lines of R code include at least a data object and a function. Functions are discussed in section 4. This chapter covers a few key data types and how to index them, followed by a brief section on if statements and for loops. The final part is a recap, which you could read first if you like. 2.1 Vectors A vector stores any number of observations of a single variable. In other words, a vector is a one-dimensional collection of data in which every element is the same type of data (think numbers versus text). Vectors are the most fundamental type of data object in R. The smallest unit of data is a one-element vector. If you type 1 + 3 into the console, R treats 1 and 3 as single-element vectors and returns a single-element vector containing 4. Some preliminaries: Coercion: R doesn’t permit different data types in the same vector. If, for example, you try to combine numbers and text, R will coerce the numbers to text (so math won’t work on them). Missing or invalid data are stored as NA for the missing elements. These can exist in any vector type and will typically produce another NA when operated on. NaN (not a number) is like NA, but represents the outcome of an impossible mathematical operation (e.g. log(-1)). Empy vectors: NULL represents a vector that exists in the environment but contains nothing. The most important vector types are: Numeric. Contain numbers. Character (AKA strings). Contain words or other text. Factor. Contain categorical variables. Logical (AKA Boolean). Binary variables containing only special element types TRUE and FALSE (and NA). Dates. 2.1.1 Numeric vectors Numeric vectors permit mathematical operations. Here, ‘numeric vectors’ is used to also refer to subtypes such as integer vectors. Things to know: Inf is a numeric value representing infinity – e.g. try typing 1 / 0. Scientific notation. As shorthand, numbers can use e to denote how many powers of 10 the number is. For example 1.2e6 is 1.2 million and 3e-4 is 0.0003. ### Numeric vectors num_vec1 &lt;- c(6, 8, -1, 10.2) # c() function (combine) creates a vector from the inputs identical(c(2), 2) # (Single-element vectors don&#39;t need to be created in c(), but can be) num_vec1 str(num_vec1) # Summarises the structure of num_vec1 length(num_vec1) num_vec1 / 3 num_vec2 &lt;- runif(n=5, min=-10, max=10) # Randomly draws from the uniform distribution num_vec2 ^ 2 num_vec1 + num_vec2 # Won&#39;t operate (or recycle) due to different vector lengths # Note that line 11 worked because the vector &#39;3&#39; was recycled 5 times. Recycling was # allowed in that instance because length 4 is a multiple of length 1. num_vec3 &lt;- runif(n=4, min=-10, max=10) num_vec1 + num_vec3 # Works because same vector length ### NA examples na_num_vec &lt;- c(1:5, NA, 7:10) # The : operator generates a vector of integers. str(na_num_vec) na_num_vec + 1:10 # Operations on NA typically produce another NA sqrt(c(9, 4, 1, 0, -1)) 2.1.2 Character vectors Character vectors can contain letters, spaces, symbols, numbers, etc. Each element is surrounded by inverted commas (either single or double, makes no difference). Things to know: Powerful functions for modifying or searching character vectors include paste(), grep() (and related operator %like%), gsub(), substr() and nchar(), and their variants. These functions can do most of the things you’ll ever want to do with text. When NA appears in a character vector, it appears as &lt;NA&gt;. ### Character vectors char_vec1 &lt;- c(&#39;put&#39;, &#39;any&#39;, &#39;TEXT&#39;, &#39;at all&#39;, &#39;in&#39;, &#39;here.&#39;) char_vec1 str(char_vec1) char_vec2 &lt;- letters # &#39;letters&#39; is an in-built vector containing the alphabet. char_vec3 &lt;- head(char_vec2, n=length(char_vec1)) # Takes the first n elements char_vec4 &lt;- paste(char_vec1, char_vec3, sep=&#39;_&#39;) # Concatenates the two vectors char_vec4 # Which elements of char_vec4 have the letter &#39;a&#39; in them? grep(&#39;a&#39;, char_vec4) # 1st, 2nd and 4th elements # Replace letter &#39;a&#39; with text &#39;_REPLACED_&#39; char_vec5 &lt;- gsub(&#39;a&#39;, &#39;_REPLACED_&#39;, char_vec4) char_vec5 # Take the first two characters from each element substr(char_vec5, start=1, stop=2) # Example of vector coercion num_vec1 &lt;- c(6, 8, -1, 0) coerced_vec &lt;- c(num_vec1, char_vec1) str(coerced_vec) # The numbers have been coerced into characters 2.1.3 Factor vectors Factors are a compressed (i.e. more efficient) version of characters, for when elements of a character vector are repeated. Think of a categorical variable such as a rating with levels ‘high’, medium’ or ‘low’. Behind the scenes, R stores a mapping of the factor levels into integers, and then stores the full factor vector as a vector of integers. Warning: Do not convert factors into numerics. It will give you these ‘keyed’ integers but discard the key. It is safe, however, to convert factors to characters, which will produce the factor levels as a character vector. ### Factor vectors fac_vec &lt;- as.factor(c(&#39;high&#39;, &#39;medium&#39;, &#39;low&#39;, &#39;medium&#39;, &#39;low&#39;, &#39;high&#39;, &#39;high&#39;)) str(fac_vec) levels(fac_vec) as.numeric(fac_vec) as.character(fac_vec) 2.1.4 Logical vectors A logical vector is a binary variable that contains only the values TRUE and FALSE (not in inverted commas), which can be shorted to T and F. Logical vectors are very useful for indexing. They are also used in if statements. Some common operators for producing logical vectors from other vectors are: ! in front of a logical vector means ‘not’ – it flips TRUE to FALSE and vice versa. == between two vectors means ‘equals’, and works element by element (see section 2.2.1). &lt; (less than), &lt;= (less than or equal to), &gt; and &gt;= work similarly to ==. Character vectors are treated as alphabetically ordered. Don’t use these operators on factors. %in%, used like vec1 %in% vec2, returns TRUE for elements of vec1 that are present in vec2 and FALSE for elements not in vec2. &amp; (and) and | (or) work between two logical vectors. which() converts a logical vector into an integer vector stating the positions of TRUE elements. ### Logical vectors log_vec1 &lt;- c(TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, TRUE) str(log_vec1) which(log_vec1) # which() returns an integer vector of the positions of TRUEs log_vec1 * 2 # T and F are converted to 0 and 1 when mathematical oeprations are applied sum(log_vec1) # So the sum of a logical vector is how many TRUEs are in it log_vec2 &lt;- c(1, 2, 5, 6, 3, 7, -1) &lt; 4 # Logical vectors can be created by conditions identical(log_vec1, log_vec2) log_vec3 &lt;- c(2, 2, 3, 2.5, 2, -2, 2) == 2 identical(log_vec1, log_vec3) identical(log_vec1, !c(F, F, T, T, F, T, F)) # The operator ! flips TRUE and FALSE. even_numbers &lt;- seq(0, 100, by=2) (1:5) %in% even_numbers # Example of %in%. Result is always same length as LHS vector. log_vec4 &lt;- c(TRUE, FALSE) log_vec5 &lt;- c(FALSE, TRUE) log_vec4 | log_vec5 log_vec4 &amp; log_vec5 2.1.5 Date vectors There are several types of date vectors in R. For now, this section just covers the simplest approach, which in some cases will not be the best, but it always works. This involves storing dates as character vectors with the format ‘yyyy-mm-dd’. Some characteristics of this approach: Simple – no package dependencies, no type-specific behaviour to understand. Just keep an eye out that R does not try to convert the vector into a factor or a non-character date format. No times – obviously this just works with calendar days, not hours, minutes, etc. Correct ordering: for example, 2021-02-01 &gt; 2021-01-31 reliably returns TRUE – and this works correctly for all dates – because R treats characters as alphabetically ordered. That is, R checks left to right along the 10 positions in each character, and as soon as there’s a position where one character is greater than then other (e.g. ‘b’ is greater than ‘a’; ‘2’ is greater than ‘1’), it determines that to be the higher character vector element. Unintelligent: While this will order dates correctly, it will usually not be able to tell you how many days or months there are between two dates. Other date types can do that. But easy to make smarter: It’s easy to write functions that manipulate these dates in useful ways. See section 4.2 for an uncomplicated function that converts any of these dates to a quarter end. Can be slow. For large datasets, it can be slow relative to other date types, for the same reason than factor vectors are more memory efficient than character vectors. 2.2 Vector operations and indexing This section discusses features of working with vectors that apply to all vector types. 2.2.1 Vector-wise operations and recycling Operations on vectors run element by element. To understand what this means, run the code chunk below. seq(1, 5, by=1) seq(1, 5, by=1) * seq(1, 5, by=1) The result of the second line above is a vector where: 1. The first element is the product of the first elements of x1 and x2, 2. The second element is the product of the second elements of x1 and x2, 3. Etc. Vector-wise operations still work if the two vectors have different lengths. There are two ways this can happen: Good: one of the vectors is length one, for example the 2 in seq(1, 6, by=1) / 2. This is handy and is used a lot. Bad: the vectors have different lengths, but neither is length one, for example seq(1, 6, by=1) / c(2, 3). Recycling. In this case, R recycles the shorter vector by repeating it until it’s the length of the longer vector. In some but not all cases a warning is shown on screen. Avoid this type of recycling. It’s better for your code to be more explicit about what it’s doing. So, for example, write seq(1, 6, by=1) / rep(c(2, 3), 3) instead of seq(1, 6, by=1) / c(2, 3). Some packages don’t let you recycle, for this reason. 2.2.2 Named vector elements Vector elements can have names. Elements can be named when the vector is created, using = with the names on the LHS, or they can be assigned afterward. # Name the elements when the vector is created num_vec_named1 &lt;- c(a=1, b=2, c=3, d=4, e=5) num_vec_named1 str(num_vec_named1) names(num_vec_named1) # Create an unnamed vector, then assign names to it. num_vec_named2 &lt;- 1:5 str(num_vec_named2) names(num_vec_named2) names(num_vec_named2) &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;) str(num_vec_named2) 2.2.3 How to index vectors Indexing is for extracting a subset of an object. Vectors are indexed with another ‘indexing vector’ inside []. For example, num_vec[2] returns just the second element of num_vec, and num_vec[c(2, 4)] returns the second and fourth elements. (The first position of a vector is 1, not 0 as in some other languages.) Inside [] can be one of: An integer vector, specifying the positions of the elements to extract. A logical vector, where TRUE in the logical vector specifies the elements to extract. A powerful tool: To extract elements based on a condition, create and index with a logical vector in a single step. Examples in the code below. Length of the indexing vector. The logical vector in the index operators should be the same length as the vector being indexed. If it isn’t, and it still works (i.e. no error), the logical vector has been ‘recycled’ to the length of the indexed vector. A character vector of names, which extracts the elements with those names. Note that num_vec[2, 4] does not work because it is providing the index operators two vectors (2 and 4) rather than one as in the case of num_vec[c(2, 4)]. Indexing best practice: once you get going with R, always try to avoid indexing with integers, for any object type. This is because often you want to add elements to vectors (and to other object types) which can end up changing element positions. Integer indexing can then return the wrong thing. If you instead index using names or conditions (i.e. logical vectors), your code will be more flexible and robust. Combine indexing with assignment to modify parts of an existing object. For example, num_vec[c(3, 4)] &lt;- 0 changes the third and fourth elements to zero. num_vec1 &lt;- runif(25, min=-1, max=1) # Create random uniform vector length 25 num_vec1 num_vec1[1] # Index with integer to extract the first element num_vec1[c(1, length(num_vec1))] # Integers to extract first and last elements num_vec2 &lt;- num_vec1[num_vec1 &gt;= 0] # Extract only the positive components num_vec2 # Give the elements names and extract based on that names(num_vec1) &lt;- letters[1:length(num_vec1)] # &#39;letters&#39; contains a to z num_vec1[c(&#39;a&#39;, &#39;y&#39;)] # Create an arbitrary vector with some NAs in it num_vec3 &lt;- c(6, 2, NA, 3.5, 11:9, NA, rep(-1, times=4), NA, seq(20, 30, by=2)) num_vec3 # Remove the NAs by creating a logical vector and indexing with it num_vec4 &lt;- num_vec3[!is.na(num_vec3)] num_vec4 # Or alternatively, combine indexing and assignment to change all the NAs to zero num_vec4 &lt;- num_vec3 num_vec4[is.na(num_vec4)] &lt;- 0 num_vec4 The other two main indexing operators are [[]] and $. We’ll come back to them. 2.3 Arrays An array is a multi-dimensional extension of a vector. A two-dimensional array is called a matrix. Arrays can also have more dimensions, although this does get used much. Data frames tend to be more useful than arrays, because in an array all columns must be the same data type, but arrays are worth a quick look, because data-frame indexing builds from array indexing. Arrays are also useful for mathematical operations. Let’s focus on two dimensional arrays (i.e. matrices). Some things worth knowing about arrays: Single data type. Like vectors, arrays can only contain a single data type, either numeric, character or logical. Arrays are indexed with a vector for each dimension, separated by commas. For example, in matrix1[vec1, vec2], vec1 specifies the rows to extract and vec2 the columns. To extract some rows and all columns, or vice versa, leave one of the dimension indexes blank, e.g. [vec1, ] or [, vec2]. The indexing vectors (e.g. vec1, vec2) can be integer, logical or character vectors, like when indexing a vector. If the array has three dimensions, it is indexed with array1[vec1, vec2, vec3], and likewise for four or more dimensions. Names. Arrays can have column names, or row names, or both. Dimension attribute. Arrays have a dimension attribute, which is an integer vector where each element specifies the length of the dimension. See the example code below. ### Arrays num_array1 &lt;- matrix(seq(10, 200, by=10), nrow=5, ncol=4) # matrix() creates a 2D array str(num_array1) # [1:5, 1:4] shows it&#39;s an array, with rows 1 to 5 and cols 1 to 4. dim(num_array1) # Dimension attribute is a two-element vector of integers. num_vec1 &lt;- seq(10, 50, by=10) dim(num_vec1) # Vectors don&#39;t have a dimension attribute num_array1 %*% 1:4 # Arrays allow matrix algebra. Matrix products are %*% (outer are %o%) # Column and row names num_array_named &lt;- matrix(seq(10, 200, by=10), nrow=5, ncol=4) colnames(num_array_named) &lt;- letters[1:4] rownames(num_array_named) &lt;- c(&#39;row1&#39;, &#39;row2&#39;, &#39;row3&#39;, &#39;row4&#39;, &#39;row5&#39;) num_array_named # Indexing num_array1[c(2, 4), ] # To include all columns, leave the column index empty num_array1[, c(2, 4)] # Vice versa for all rows num_array_named[&#39;row2&#39;, &#39;c&#39;] # Index with row and column names num_array_named[2, c(3, 4)] # Index with row and column integers num_array_named[1:2, c(&#39;a&#39;, &#39;b&#39;)] # Index with row integers and column names The base R ‘Titanic’ dataset gives an example of an multi-dimensional array – it has 4 dimensions. It has a matrix for each value of {Adult, Child}, and for each value of {Survived Yes, Surivived No}. Titanic dim(Titanic) Titanic[, , , &#39;Yes&#39;] # Slice only 1 val from 4th dimension to return 3D object Titanic[, , &#39;Adult&#39;, &#39;Yes&#39;] # Slice vals from 3rd and 4th dimensions to return 2D object Titanic[, &#39;Female&#39;, &#39;Adult&#39;, &#39;Yes&#39;] # Return 1D object (i.e. vector) Titanic[&#39;Crew&#39;, &#39;Female&#39;, &#39;Adult&#39;, &#39;Yes&#39;] # Return zero dimension object (i.e. scalar) 2.4 Data frames A data frame stores a dataset. It’s likely to be the object type you use most. The following information is about base R data frames, but also applies to data tables and tibbles. Some characteristics of data frames: A data frame is a collection of same-length vectors, laid out as columns. Columns can be different data types (unlike arrays). The columns usually have names (e.g. the names of the variables in the dataset). Data frames can be indexed like arrays, using [, ]. See the discussion of arrays and vectors above. Individual columns can also be indexed with the dollar symbol $. For example, df$col returns the column named ‘col’ from the data frame named ‘df’. Data frames (in base R) can have row names but it’s typically considered best practice to not use them. ### Dataframes # Base R comes with a few example datasets, including a data frame called &#39;iris&#39;. # (Run &#39;data()&#39; to see all example datasets.) df1 &lt;- iris head(df1) # Head and tail pull out the beginning and end of data frames (or vectors). tail(df1, 10) # The second argument is how many to show. Default is 6. dim(df1) str(df1) colnames(df1) # Indexing a single column returns it as a vector head(df1$Species) df1$Sepal.Length[2:3] # Indexing multiple columns returns a smaller dataframe df2 &lt;- df1[1:11, grepl(&#39;Petal&#39;, colnames(df1))] str(df2) # Index the rows with a logical vector that conditions on a column df1[df1$Sepal.Width &gt; 3.5, ] # Say we know virginica cannot have sepal width above 3.5, so they must be errors. df_corrected &lt;- df1 df_corrected[df_corrected$Sepal.Width &gt; 3.5, &#39;Species&#39;] &lt;- NA df_corrected 2.5 Lists A list is a collection of any R objects. A list is like a vector, in that it is a one-dimensional collection of elements. However, the elements can each be anything (e.g. a whole datasets, or another list), and, within the same list, can be different types of objects. Some characteristics of lists: List elements can have names. Lists can be indexed with a single integer/logical/character vector inside[ ], just like how vectors are indexed. If the elements are named, they can also be indexed with $, like the column of a data frame. A single element of a list can also be indexed with [[ ]]. This is slightly different to indexing a single element with []. Double brackets return the element as its own object type; single brackets return a one-element list with the object inside it. Sometimes lists are also called vectors, with single-variable vectors distinguished as ‘atomic vectors’. This document only uses ‘vector’ to mean a single-variable vector. : indexing with $ uses partial matching, which can cause mistakes if you don’t keep careful track of your names (which most don’t). TO avoid this you can write options(\"warnPartialMatchDollar\"=TRUE) at the beginning of your scripts, so that you get a warning whenever partial matching is used. ### Lists # Put several types of objects into the same list num_vec1 &lt;- c(6, 8, -1, 10.2) char_vec1 &lt;- c(&#39;put&#39;, &#39;any&#39;, &#39;TEXT&#39;, &#39;at all&#39;, &#39;in&#39;, &#39;here.&#39;) num_array1 &lt;- matrix(seq(10, 200, by=10), nrow=5, ncol=4) list1 &lt;- list(num_vec1, char_vec1, num_array1) list1 str(list1) # Index the list a few different ways list1[c(1, 2)] # Returns a two-element list list1[2] # Returns a one-element list containing only the second element list1[[2]] # Returns the vector inside the second element list1[[c(1, 2)]] # CAREFUL - a vector inside [[]] does not do what you might expect. This # takes the second element of the first element, not the first and second elements. list1[is.numeric(list1)] # Give the list names names(list1) &lt;- c(&#39;num_vec1&#39;, &#39;char_vec1&#39;, &#39;array1&#39;) str(list1) # Index it with the names list1$char_vec1 list1[&#39;char_vec1&#39;] list1[[&#39;char_vec1&#39;]] # Combine assignment with indexing to modify an element list1$char_vec1 &lt;- c(&#39;You&#39;, &#39;can&#39;, list1$char_vec1) list1[[&#39;char_vec1&#39;]] # Combine indexing and assignment to add an element list1$num_vec2 &lt;- 100:109 str(list1) # Index with a logical vector, to pull out any elements with &#39;vec&#39; in their name. list1[grepl(&#39;vec&#39;, names(list1))] 2.6 ‘If’ statements and ‘for’ loops If statements and for loops both fall in the category called ‘control flows’. Another type of loop not covered here is the ‘while’ loop, which is like a for loop, but stops iterating once some condition is satisfied. 2.6.1 If statements An if statement is essentially a chunk of code gated off by a switch. If the switch is set to TRUE the code runs, and if it’s set to FALSE it doesn’t. If statements always look something like: # This code won&#39;t actually run, it&#39;s just illustrative if(&lt;single-element logical vector&gt;) { &lt;one or more lines of code&gt; } # or if(&lt;single-element logical vector&gt;) &lt;single line of code&gt; Some working examples: run_code &lt;- FALSE x &lt;- 1 y &lt;- 100 if(run_code) { x &lt;- x + 1 y &lt;- y + 1 } x y # Again but the statement is not bypassed run_code &lt;- TRUE if(run_code) { x &lt;- x + 1 y &lt;- y + 1 } x y # If statements are most useful when the TRUE/FALSE is generated within the code x &lt;- rnorm(100) summary(x) if(any(x &gt; 1.5)) x &lt;- x - 0.5 summary(x) The ifelse() function works similar to an if statement. Functions are discussed further in section 4. 2.6.2 For loops For loops iteratively apply the same operation to multiple things. For loops produce the results from one iteration before stepping to the next, and are most useful when the operations need to use results from previous iterations. Alternatively, when each iteration can be run independently, there are usually better ways than using a for loop. Namely, ‘vectorised’ functions, which do the same thing to every element in a vector, or the ‘apply’ family of functions (see section 4.4), which apply a chosen function to every element in some other object. These alternatives tend to run faster – sometimes by a lot – and keep the code cleaner and more reliable. For loops always look something like: # This code won&#39;t actually run, it&#39;s just illustrative for(&lt;arbitrary name&gt; in &lt;loop vector&gt;) { &lt;line/s of code to run in each iteration&gt; &lt;code should reference &#39;abritrary name&#39;&gt; } In the first iteration, the code inside the loop treats replaces the ‘arbitrary name’ object with the first element in the ‘loop vector’, in the second iteration it’s replaced with the second element, and so on for all elements of the loop vector. # Inappropriate use of a for loop x &lt;- 1:100 x_log1 &lt;- c() # Set up an empty vector for(i in 1:length(x)) { x_log1[i] &lt;- log(x[i]) } plot(x, x_log1) # Better alternative: log() is vectorised, so the loop is not needed. x_log2 &lt;- log(x) plot(x, x_log2) # Potentially appropriate use of a for loop - turning a vector into cumulative x_cumul1 &lt;- c() # But this runs slower than doing it as in the next line x_cumul1 &lt;- rep(NA, length(x)) # Faster if the initialised object has the correct length x_cumul1[1] &lt;- x[1] for(i in 2:length(x)) x_cumul1[i] &lt;- x_cumul1[i-1] + x[i] # But still not a great way, because there&#39;s a vectorised base R function for that. x_cumul2 &lt;- cumsum(x) identical(x_cumul1, x_cumul2) 2.7 Recap Here’s a quick recap of the main data object types discussed in this section, and how to index them: Vectors store a single variable, and are R’s most fundamental type of data object. Types. Vector types include numeric, character, logical and factor (i.e. categorical variables). Indexing. To index a vector vec1, type vec1[vec2] where vec2 is an integer, logical or character vector. Indexing with characters only works on named vectors. Data frames – including popular extensions ‘data tables’ and ‘tibbles’ – store datasets, that is, collections of related variables that can be different types. Names. Can have column names and/or row names. Using row names is generally discouraged. Indexing. Indexed with [, ], similar to vectors, or with $ to index an individual column. df[vec1, vec2] indexes the vec1 rows and the vec2 columns. df[vec1, ] indexes all columns and vec1 rows, and df[, vec2] the reverse. df$col extracts the column named col1, as a vector. Two-dimensional arrays are like data frames but all elements must be the same type. Arrays can also have more dimensions. Lists are a more-flexible vector type whose elements can each be any object type (e.g. each element of a list can be a different dataset). Lists are indexed with [[]], [] or $. If vec1 is a single-element vector, list1[[vec1]] extracts the element vec1 refers to, as its own object. list1[vec1] returns a list containing the elements of list1 referred to by vec1. list1$element1 returns the element of list1 named element1, as its own object. "],["sourcing-data.html", "Chapter 3 Sourcing data 3.1 Common functions for importing data 3.2 Where to save data 3.3 Setting up an RStudio project", " Chapter 3 Sourcing data Most R data analysis involves working on data that is read from somewhere, such as a local saved file or an online source. This chapter covers ways of reading data, and where to store them. 3.1 Common functions for importing data Common functions for importing data include the following. They are all good options. I tend to use fread() for csv files and read.xlsx for Excel files. read.table() from base R. Reads most types of text files. read.csv() from base R. A version of read.table() specifically for csv files. read.xlsx() from the openxlsx package. Reads a worksheet from an excel file, including from an online source (i.e. the location is a website). fread() from the data.table package. Reads a csv file (and some other file types) in as a data table, much faster than read.csv(). Can read from a local file or an online source. This is usually the best options if speed is an objective. read_csv() from the readr package, part of Tidyverse. Reads a csv file in as a tibble. read_excel() from the readxl package, part of Tidyverse. Reads a worksheet of an excel file, in as a tibble. For online sources, openxlsx::read.xlsx() tends to be easier. To save data from your R session to a local location in a common file format, use the functions above but replace read with write, for example, write.csv() or fwrite(). To save R objects for use in a later R session, read and write them as a ‘.rds’ file type using readRDS and writeRDS. 3.2 Where to save data There are three options for specifying where to save data: Bad: Use setwd() to set a working directory for your R session. R will then treat addresses as subfolders within that directory, so the full address does not need to be written. This is generally discouraged because it gives your script an external dependency that reduces the flexibility of your work. For example, others will probably not be able to run your code on their machine. Good: Use an RStudio project, which bundles related script/s and files in a self-contained folder that can be moved and run anywhere. R treats the project folder as the working directory regardless of where the project folder is put. R projects are an RStudio feature and are discussed further in section 3.3. Sometimes necessary: write the full filepath of the location. This is required if you need to write to a specific location on your machine/network. ### Reading and writing data from local location # Gets the location of your script. Just so the example works in this setting. local_folder &lt;- dirname(rstudioapi::getSourceEditorContext()$path) # Write the iris dataset as a local csv file. Double click the saved file to check it&#39;s # been written. write.csv(iris, file=paste0(local_folder, &#39;/iris_dataset.csv&#39;), row.names=FALSE) # Read it back into your R session iris_dataset &lt;- read.csv(paste0(local_folder, &#39;/iris_dataset.csv&#39;)) str(iris_dataset) # (Remove the saved file jsut to clean up) file.remove(paste0(local_folder, &#39;/iris_dataset.csv&#39;)) ### Reading data from online # Uncomment and run next line if openxlsx package has never been installed #install.packages(&#39;openxlsx&#39;) mysuper_data_locn &lt;- paste0(&#39;https://www.apra.gov.au/sites/default/files/2022-03/&#39;, &#39;Quarterly%20MySuper%20statistics%20September%202019%20-%20December%202021.xlsx&#39;) sheet_name &lt;- &#39;Table 1a&#39; mysuper_data &lt;- openxlsx::read.xlsx(xlsxFile=mysuper_data_locn, sheet=sheet_name, startRow=4) # These data need to be cleaned (e.g. rows removed, columns renamed) before they&#39;re # usable. But just look at a bit of it to see that the data pull worked. dim(mysuper_data) mysuper_data[1:5, 1:5] 3.3 Setting up an RStudio project RStudio projects are suitable for all coding tasks. The project creates a folder for containing the scripts and other files used for that task, such as locally stored datasets. Inside the folder is a .Rproj file that coordinates the project’s files. To create an RStudio project: Open RStudio, click ‘File’, ‘New Project’, ‘New Directory’, then ‘New Project’. Write a name for the project folder (‘Directory name’), then click ‘Browse’ and pick a folder to put the project folder in (anywhere is fine), then click ‘Create Project’. The empty project wll open, and the ‘Files’ tab in the ‘Files, Plots, Packages, …’ pane will show no files in the project folder aside from the ‘.Rproj’ file you just created. In a sense this file coordinates the other files in the project. Click ctrl + shift + N to open a new script, then click ‘File’ then ‘Save As’ to save it into your project folder and give it a name. It will then appear in the ‘Files’ window. The project folder is now the working directory to which any R scripts in that folder reference. Move any other files or scripts that are for that task into the project folder. The following code works fine in a script in an RStudio project. It puts the data in the project folder then reads it back from the project folder. ### Don&#39;t run this code unless you&#39;re in an RStudio project. Not sure where it will put ### the csv file otherwise. write.csv(iris, file=&#39;iris_dataset.csv&#39;, row.names=FALSE) iris_dataset &lt;- read.csv(&#39;iris_dataset.csv&#39;) # To delete the file you just created, uncomment and run the next line: #file.remove(&#39;iris_dataset.csv&#39;) A key benefit of RStudio projects is that it keeps your task self contained. The project will keep working if you move it, including giving it to someone else. 3.3.1 When to use packages instead of projects Creating and working in a package is an alternative to working in a project. A package is a collection of functions intended to be easily shared with others, stored in a self-contained bundle like a project. Packages are useful when the point of your work is to allow others to use your code without having to think about how your code works. Keep the option in mind, but as a data analyst, you’ll probably find that most of your work does not fit in that category. Packages are a bit more complicated to set up and use, and impose some requirements on what files and scripts you use, and where you put them. So unless you want the practice, projects are in many cases a more suitable option. Sometimes it’s important that the analyst that runs the code has reasonable familiarity with how the code works, in which case a package is unsuitable. A common example is code that comprises a model that has assumptions that would be misapplied if the user does not understand them. In these cases the primary benefit of developing a package – preventing the user from having to deal with the underlying code – turns into a cost. "],["functions.html", "Chapter 4 Functions (and environments) 4.1 Using functions 4.2 How to write functions 4.3 Environments 4.4 Applying functions repeatedly 4.5 Debugging user-defined functions", " Chapter 4 Functions (and environments) Functions convert inputs into outputs. Every function call, such as runif(n=5, min=-10, max=10), has two key components: The function name, in this case runif, which is short for ‘random uniform distribution’. The function arguments written inside parenthesis after the name and separated by commas. In this case the arguments are n, min and max. Different functions have different arguments. 4.1 Using functions To get the description of a function and its arguments, type ?&lt;function name&gt; into the console – for example, ?runif. The help file will open in RStudio’s ‘Help’ pane. Try it. Some things to know about function arguments: Argument names don’t have to be written when calling the function; for example, runif(n=5, min=-10, max=10) does the same thing as runif(5, -10, 10). If you provide the arguments without names, R will assume the arguments are in the same order as in the function definition (i.e. as written in the help file). Default arguments. Many functions have arguments that don’t need to be specified by the user because they have default vaues. The help file tells you which arguments have defaults – if the argument name is followed by = then a value, then that argument has a default of that value. For example, runif(5, 0, 1) does the same thing as runif(5). Dot dot dot (i.e. ...). In a function definition, ... means that any number of arguments can be provided. For example, look up the help file for c(). In this case, the function will combine whatever arguments are provided. Some functions don’t need arguments, but the parentheses must still be written. For example, c() generates an empty vector, which is sometimes used to initialise an object before putting things in it. Operators are functions too. Operators like + or [] are just functions that take their arguments differently. They can be expressed in the same form as other functions, with the use of backticks ` `. For example, 1 + 2 is the same as `+`(1, 2) and seq(101, 105)[3] is the same as `[`(seq(101, 105), 3). 4.2 How to write functions It’s easy to write your own functions, and the more you use R the more you’ll do it. Running code that defines a function – i.e. assigns the written function to the name you give it – puts that function in your environment available to be called upon, like assigning a data object. Each function has a name, arguments (if any), a body and an output. Defining a function involves writing some version of the following: # This code won&#39;t actually run because the function body is not actual code. function_name &lt;- function(function_arguments) { &lt;function_body: operations on function_arguments that produce output_object&gt; return(output_object) } A simple example that works: double_F &lt;- function(x) { # I use _F in my own function names for convenience. y &lt;- x * 2 return(y) } double_F(3) double_F(7.5) double_F(1:6) # This works because the operation in the body of double_F works on a # numerical x vector of any length. Some things worth knowing about user-defined functions: The ‘return’ line isn’t always needed. If the function has no return value, and the last line in the function is not an assignment, the function will return the result of the operation in the last line. The squiggly brackets {} also aren’t needed, if the function definition fits in one line. So, for example, double_F &lt;- function(x) x * 2 works just as well as the example above. Try it. Single-line functions can be useful, as demonstrated in section 4.4. The argument names have no consequence. For example, fun1 &lt;- function(x) x * 2 and fun2 &lt;- function(z) z * 2 and fun3 &lt;- function(push_the_envelope_watch_it_bend) push_the_envelope_watch_it_bend * 2 do identical things. But, as always, try choose the names to make it easy for a reader to understand what the function is doing. x is a commonly used argument name because it references the typical mathematical function definition \\(y=f(x)\\). The output can be only a single object. If you need your function to return multiple objects, store them as elements of the same list, and return that list. The output does not need to utilise the arguments. For example, the function fun4 &lt;- function(x) 7 is a legitimate function, and will return 7 whenever it is called, regardless of what x argument is provided. Try it. ### Example of a function that I sometimes use. quarterendify_F &lt;- function(datevec, as_numeric=FALSE) { # Converts character dates to the end of the quarter that they&#39;re in. # Arguments: # - datevec: character vector in &#39;yyyy-mm-dd&#39; format # - as_numeric: if TRUE, returns the date as numeric vector in yyyymmdd format. # Generate error if some formatting conditions are not met. if(any(nchar(datevec) != 10)) stop(&#39;Some datevec in wrong format: not 10 characters.&#39;) if(any(substr(datevec, 5, 5) != &#39;-&#39; | substr(datevec, 8, 8) != &#39;-&#39;)) { stop(&#39;Some datevec in wrong format: do not have \\&#39;-\\&#39; in 5th and 8th positions.&#39;) } # Could write in more of these - e.g. make sure mm is &lt;= 12 and dd &lt;= 31. # Logical vector of which dates need replacing, i.e. are not already quarter ends chng_B &lt;- !substr(datevec, 6, 10) %in% c(&#39;03-31&#39;, &#39;06-30&#39;, &#39;09-30&#39;, &#39;12-31&#39;) # Start generating replacement dates. First change the months. repl &lt;- datevec[chng_B] repl &lt;- sub(&#39;-01-|-02-&#39;, &#39;-03-&#39;, repl) # When 1st sub argument has &#39;|&#39; in it, it&#39;s treated as &#39;or&#39; (i.e. looks for either). repl &lt;- sub(&#39;-04-|-05-&#39;, &#39;-06-&#39;, repl) repl &lt;- sub(&#39;-07-|-08-&#39;, &#39;-09-&#39;, repl) repl &lt;- sub(&#39;-10-|-11-&#39;, &#39;-12-&#39;, repl) # Identify which repl elements have June and Sep quarters. _B in name denotes boolean. jun_n_sep_B &lt;- substr(repl, 6, 7) %in% c(&#39;06&#39;, &#39;09&#39;) # Add &#39;-dd&#39; in for June and Sep qtrs, then March and Dec qtr repl[jun_n_sep_B] &lt;- paste0(substr(repl[jun_n_sep_B], 1, 8), &#39;30&#39;) repl[!jun_n_sep_B] &lt;- paste0(substr(repl[!jun_n_sep_B], 1, 8), &#39;31&#39;) # Generate and populate output vector &#39;y&#39; y &lt;- datevec y[chng_B] &lt;- repl # If argument not set to default, convert to numeric yyyymmdd format. if(as_numeric) y &lt;- as.numeric(gsub(&#39;-&#39;, &#39;&#39;, y)) return(y) } # Demonstrate it quarterendify_F(c(&#39;2021-03-30&#39;, &#39;2021-03-31&#39;, &#39;2021-04-01&#39;)) quarterendify_F(c(&#39;2021-03-30&#39;, &#39;2021-03-31&#39;, &#39;2021-04-01&#39;), as_numeric=TRUE) quarterendify_F(c(&#39;2021-03-30&#39;, &#39;2021-03-31&#39;, &#39;2021-04-1&#39;)) quarterendify_F(c(&#39;30-03-2021&#39;, &#39;31-03-2021&#39;, &#39;01-04-2021&#39;)) When R runs a function it works through the following process: Starts working through the operations inside the function definition, in this case y &lt;- x * 2 If it encounters any objects that haven’t been defined inside the body, checks if these objects are function arguments, which, in this case, x is. Continues the operations using any such required function arguments, and stores any newly assigned objects in the environment. Returns the object specified in the return line. 4.2.1 Why put your operations inside user-defined functions? Four reasons (at least): Less code to write. If you’re running the same set of operations multiple times, putting them into a function means they only have to be written once, when defining the function. The subsequent runs can call that function. Lower likelihood of mistakes. If the set of operations is written only once, there’s only one place you need to check for errors. Keeps the global environment clean. There’s more on this in section 4.3. Operations in functions can assign and use new objects without any concern about affecting the global environment. Allows neater code. Functions are a neat way of grouping self-contained sets of operations together, which can be very helpful for keeping the contents of scripts neatly organised. 4.3 Environments The ‘environment’ is what contains the objects that are on hand to use (sometimes called the ‘frame’ for the objects). When you open an R session, you will be operating in the global environment. Open the ‘Environment’ pane in RStudio, and you will see that when you assign objects, they will appear in the global environment. These objects include data objects and functions. Each time a function is run, that function temporarily creates its own local environment, which disappears once the function has completed running. All objects that were assigned in operations inside the functions disappear with it. The only object that passes back to the enclosing (e.g. global) environment is the specified return value. In other words, functions clean up after themselves. This is true for user-defined functions and for predefined functions. Environments are hierarchical: when a function is called from the global environment, its local environment is enclosed within the global environment. Functions often also call other functions (e.g. the `*` function in double_F above). If one function calls a second function, the second function’s local environment is enclosed within the first function’s local environment. So you can have a global environment enclosing a local environment, which encloses another local environment, which encloses another, etc. What does this hierarchy mean in practical terms? It’s mainly about how objects are looked for, or ‘scoped’. It was already noted that the global environment cannot access objects created within a local environment enclosed within it. (When your running code moves back to the global environment, the local environment will be gone.) The reverse is not true. Local environments can access objects in any environments that enclose them. For example, objects assigned in the global environment will be available to use in any local environment that exists (temporarily) within that global environment. The main implication of the hierarchy is that when the function encounters an object name in its body and looks for the object its attached to (i.e. step 2 in section 4.2 above), the hierarchy is followed: Objects are first looked for in the function arguments, and if found, they are used. If not in the function arguments, objects are looked for in the enclosing environment one level up. If not found one level up, objects are looked for in the enclosing environment two levels up. etc. Therefore, functions can use objects that exist in the enclosing environment, without having to pass them through as arguments. However, it’s best practice to pass the objects as arguments, because then the function’s operations do not depend on the state of the environment in which it was called. Doing otherwise is an easy way to introduce mistakes. One exception is when the objects being accessed from higher environments are functions (e.g. user-defined functions defined in the global environment). This is standard practice and doing otherwise would get a bit infeasible. The namespace environment was briefly mentioned in section 1.2. Put simply, it contains all the base R functions and any functions loaded in with packages, and encloses the global environment. The namsepace environment sits above (i.e. encloses) the global environment, and contains all the base functions and functions that have been loaded in from packages. This document focuses on using R for analysing data, for which the software development side of things is not particularly relevant. If you delve into the development side of R, you’ll encounter a lot more intricate details about environments. 4.4 Applying functions repeatedly The ‘apply’ family of functions – e.g. lapply() – run functions on multiple elements simultaneously. They’re usually a better alternative to loops (see section 2.6.2): instead of writing a code chunk inside a for loop, write it inside a user-defined function, then run that function on all the desired objects/elements with lapply() (or another apply function). Apply functions are useful in several situations: Whenever a loop would be useful and the loop iterations are not recursive (i.e. the iterations do not require outcomes from previous loop iterations). Sometimes you want to do the same thing to multiple rows or columns of a data frame, and no function exists that does it all at once. In this case you can take or write a function that works on one row or column, and run that function in lapply/apply/etc. Sometimes you have a list of datasets and want to run the same function on each dataset. For example, simulation models I’ve worked on have a data frame of results for each simulated entity (e.g. each bank), stored together in a list. To run simulations, you can write a function that runs on one entity, then run it on all entities with lapply(). The apply family comprises, in order of usefulness: lapply() AKA list apply. Runs a function on every element of a list (or vector) and returns a list of the results. mapply() AKA multivariate apply. Takes two or more lists of the same length, and does the same thing as lapply(), but running the function on the corresponding elements from each of the lists. sapply()AKA simplify apply. Same as lapply() but tries to ‘simplify’ the output from a list to a matrix or vector. Careful: sapply() can be a bit unpredictable in the format that it returns results. It’s often better to combine unlist() with lapply(), to turn the list output into a vector. apply(). Runs a function on every row, or every column, of a data frame or matrix, and tries to return a matrix. People often prefer using lapply() because its syntax is neater. The following examples will focus on lapply(). Run ?lapply and you’ll see the arguments are: X: A vector or list. The function specified in FUN will be run on each element of this vector or list, one at a time. Specifically, these elements will each be used as the first argument into that function. FUN: The function to apply. If it’s a one-liner user-defined function, one option is to defined is inside the call to lapply. …: Any other arguments that also need to be passed to FUN, but are the same each time FUN is called (i.e. there is no iteration for them). # Say we want the product of each row from the iris dataset (excluding the Species column) # Vectorised functions exist for the sum and mean (rowSums() and rowMeans()), but not for # the product. # Note that this is much easier in data.table, but it&#39;s worth working through to get # familiar with lapply(). ### Option 1 - lapply with pre-written single-argument function # First write a function that does the calculation on one row rowprod_F1 &lt;- function(row_num) { # Grab the elements to take the product of iris_row &lt;- iris[row_num, colnames(iris) != &#39;Species&#39;] # Calcuate the product result &lt;- prod(iris_row) return(result) } # Then run it on all rows with lapply() rowprods1 &lt;- lapply(1:nrow(iris), # Each element of this will be used as the first # argument into the function specified next. rowprod_F) # The function to apply. rowprods1 &lt;- unlist(rowprods1) # Convert the output from list to vector ### Option 2 - lapply() with pre-written double-argument function. # Notice that rowprod_F1 read iris from the global environment. It&#39;s best practice to # explicitly pass objects like this in as function arguments. The following does that. rowprod_F2 &lt;- function(row_num, iris_dataset) { iris_row &lt;- iris_dataset[row_num, colnames(iris_dataset) != &#39;Species&#39;] result &lt;- prod(iris_row) return(result) } rowprods2 &lt;- lapply(1:nrow(iris), rowprod_F2, iris) # Passed as the second argument for FUN, and not iterated over. rowprods2 &lt;- unlist(rowprods2) ### Option 3 - lapply() with a one liner # Will use shorter function argument names to make it a bit more compact rowprods3 &lt;- lapply(1:nrow(iris), function(i, data) prod(data[i, colnames(data) != &#39;Species&#39;]), iris) rowprods3 &lt;- unlist(rowprods3) identical(rowprods1, rowprods2, rowprods3) ### Alternative exercise - lapply() on a list of datasets. # Say we have a lsit of datasets and want the dimensions of each one. # Create the hypothetical list dataset_L &lt;- list(iris, mtcars, cars) data_dims &lt;- lapply(dataset_L, dim) data_dims 4.5 Debugging user-defined functions In general, the first – and sometimes only – step in debugging is to work out exactly which piece of code is causing the problem. Often this involves stepping through the code one line at a time, and checking the output of each line, to see where things have gone wrong. Once the problem is located, it can be understood and fixed. The following information may be more useful to come back to once you’re writing your own functions and need to debug one. 4.5.1 The browser() function When the code is inside a user-defined function, this is a bit less simple, because how do you step through each line one a time when all lines are run together as part of a function? The solution is the browser() function, which allows you to step into and explore the local environment inside a function. The process for using it is: Have a user-defined function that you want to explore for a bug. Write browser() as a line in that function and then re-run the function definition. Re-run the function as you did before you noticed the bug. When the code hits browser(), it will stop running, and open the local environment at that spot. Consider one of the lapply() examples above: rowprod_F2 &lt;- function(row_num, iris_dataset) { iris_row &lt;- iris_dataset[row_num, colnames(iris_dataset) != &#39;species&#39;] result &lt;- prod(iris_row) return(result) } rowprods2 &lt;- lapply(1:nrow(iris), rowprod_F2, iris) # Getting an error. Run the following. rowprod_F2 &lt;- function(row_num, iris_dataset) { browser() iris_row &lt;- iris_dataset[row_num, colnames(iris_dataset) != &#39;species&#39;] result &lt;- prod(iris_row) return(result) } rowprods2 &lt;- lapply(1:nrow(iris), rowprod_F2, iris) # The local environment will then show up in RStudio&#39;s &#39;Environment&#39; pane, showing only # the arguments passed into the function. # - Then run the code in each line of the function one at a time. # - You&#39;ll notice that the problem is in the first line, in the assignment of &#39;iris_row&#39;. # - Then try running &#39;iris_row &lt;- iris_dataset[row_num, ]&#39; to see if the problem is in the # row indexing. It&#39;s not. # - Then try running &#39;iris_row &lt;- iris_dataset[, colnames(iris_dataset) != &#39;species&#39;]&#39; to # see if the problem is in the column indexing. It is. # - Run &#39;colnames(iris_dataset) != &#39;species&#39;&#39; to check the if the logical column-indexing # vector is giving all columns except &#39;species&#39;. # - It is, but &#39;species&#39; has a capital &#39;S&#39;. Problem solved. 4.5.2 The error=recover setting If this option is switched on by running options(error=recover) then whenever your code produces an error, RStudio will give you the option to enter the local environment where the error occurred (or any environment enclosing it). Sometimes it gives you more options for different environments than you’d like, and it takes some trial and error to work out the desired one. To switch it off, run: options(error=NULL) "],["data-table-and-magrittr.html", "Chapter 5 The data.table and magrittr packages 5.1 First load the two packages 5.2 The magrittr package, AKA pipes 5.3 The data.table package 5.4 Combining data.table and magrittr 5.5 Why data.table rather than dplyr here", " Chapter 5 The data.table and magrittr packages This section covers two particularly useful packages: data.table and magrittr. The data.table package brings in functionality, speed and neatness for working on datasets. The magrittr package allows you to write your functions inside out, which makes it easy and neat to run a sequence of operations on a dataset in one go. 5.1 First load the two packages The code in the rest of this section assumes that you have data.table and magrittr loaded. If you haven’t installed them already, or if you’re not sure, run: install.packages(c(&#39;magrittr&#39;, &#39;data.table&#39;)) Now, whether you’ve loaded them in the past or not, load them into your current session by running: library(magrittr) library(data.table) 5.2 The magrittr package, AKA pipes The magrittr packages brings in the pipe operator %&gt;%. It does one thing: permits a function argument to be written before the function, to make your code look nicer. For example: unique(cars$speed) # Calling &#39;unique()&#39; the usual way cars$speed %&gt;% unique() # The pipes way. Gives exactly the same result. It works on any number of nested functions, and reads from left to right, so the result from calling one function is the argument in the next: median(unique(cars$speed)) cars$speed %&gt;% unique %&gt;% median # Brackets after the function names are not necessary You can feed other arguments into the functions: cars$speed %&gt;% unique(incomparables=c(24)) %&gt;% median By default, the object to the left of %&gt;% is the first argument in the function to the right, but it does not need to be. Just use a dot . to state which argument you want it to be: cars$speed %&gt;% unique %&gt;% median %&gt;% c(1, .) These examples feed a vector through the pipes, but pipes worth with any type of data object. Pipes with data tables are discussed in section 5.4. 5.3 The data.table package The data.table package introduces a new object type, called a data table, that is an extension of a data frame. It adds functionality, reduces the amount of code required, and executes code faster than other types of data frames. Syntactically, the main difference from base R is that more things can be done inside the index operators []. It also introduces a new type of assignment operator := for use inside the index operators. A benefit of data.table is that its help documentation is relatively thorough and easy to find: The description of arguments in the help file (see ?data.table) provides detailed information on what can be done inside []. The data.table FAQ page is good: https://cran.r-project.org/web/packages/data.table/vignettes/datatable-faq.html. Most things that work on data frames also work on data tables. The following lists some of the main additional features of data tables. There is additional handy information here: https://riptutorial.com/data-table. 5.3.1 Row and column indexing utilises shortcuts Inside index operators [], data tables recognise columns as separate named objects. To index particular rows based on values in a column, data frames require writing (for example) dataframe[dataframe$col1 &gt; 2, ], whereas data tables accept datatable[col1 &gt; 2, ]. This makes the code shorter (always a good thing), and easier to read and write. Here’s a more reproduceable example. It selects all rows from the iris dataset that have species equal to setosa and sepal length above 5. # Set up data frame and data table to compare. dataframe1 &lt;- iris datatable1 &lt;- as.data.table(iris) str(dataframe1) str(datatable1) ### Demonstration of data.table column recognition by name # The data frame way. To create the logical vector/s for indexing the desired rows, # the columns being conditioned on must first be extracted as a vector, with $. result_df &lt;- dataframe1[dataframe1$Species == &#39;setosa&#39; &amp; dataframe1$Sepal.Length &gt; 5, ] # The following doesn&#39;t work, because Species and Sepal.Length are not themselves # objects available in the environment. result_df &lt;- dataframe1[Species == &#39;setosa&#39; &amp; Sepal.Length &gt; 5, ] # The data table way. Inside [], columns are recognised as their own named objects. result_dt &lt;- datatable1[Species == &#39;setosa&#39; &amp; Sepal.Length &gt; 5, ] The way it works is that data.table basically opens its own local environment within the index operators []. In this local environment, columns are recognised as objects. dataframe1 &lt;- iris datatable1 &lt;- iris %&gt;% as.data.table Sepal.Length &lt;- rep(100, nrow(iris)) # Put object with same column name in global env. str(dataframe1[Sepal.Length == 100, ]) # Data frame uses that object str(datatable1[Sepal.Length == 100]) # Data table follows the environment hierarchy, # by first looking for (and finding) Sepal.Length inside []. # Note that when there&#39;s no argument after the comma in [, ], data.table lets you omit it Columns are treated like a list of vectors Similar to indexing rows, when indexing columns, the column names do not need to be provided as strings. The columns are recognised as objects. dataframe1 &lt;- iris datatable1 &lt;- iris %&gt;% as.data.table dataframe1[1:5, &#39;Species&#39;] dataframe1[1:5, Species] datatable1[1:5, Species] The indexing above extracts the data table column and provides it as a vector. To retain the data table structure, write the column names inside a list. The list can include any number of columns. datatable1 &lt;- iris %&gt;% as.data.table datatable1[1:5, list(Species)] datatable1[1:5, list(Species, Sepal.Length)] datatable1[1:5, .(Species, Sepal.Length)] # data.table&#39;s [] recognise . as short for list Data table’s default column indexing does not always allow indexing columns with a logical vector. You may want to use this kind of indexing if you’re systematic about how you name your columns. To get it to work with a data table, set data.table’s with argument to FALSE. This makes the data table more like a data frame by switching off the way it treats [] as its own local environment. df1 &lt;- iris dt1 &lt;- iris %&gt;% as.data.table df1[1:5, grepl(&#39;Sepal.&#39;, colnames(df1))] # Pull out columns with &#39;Sepal.&#39; in name dt1[1:5, grepl(&#39;Sepal.&#39;, colnames(dt1))] # Doesn&#39;t work properly by default in data.table dt1[1:5, grepl(&#39;Sepal.&#39;, colnames(dt1)), with=FALSE] # Does now. 5.3.2 The in-place assignment operator := Data.table’s := operator adds columns quickly. It is probably the largest deviation from base R syntax, because the standard assignment operator &lt;- is such a fundamental piece of R code. In-place assignment is used after the first comma in the indexing operator [] (i.e. ‘j’ in the help file). The := operator never removes existing columns. It either overwrites existing columns, if the name/s provided to the left are pre-existing columns, or adds new ones, if the name/s are not. dt1 &lt;- iris %&gt;% as.data.table dt1[, sepal_area := Sepal.Length * Sepal.Width] dt1 To add multiple columns, provide the new columns in a list, and assign them to a character vector of new column names: dt1 &lt;- iris %&gt;% as.data.table dt1[, c(&#39;sepal_area&#39;, &#39;petal_area&#39;) := .(Sepal.Length * Sepal.Width, Petal.Length * Petal.Width)] dt1 Since := never removes existing columns, if the new column assigned is not as long as existing columns, it will be recycled to make it fit. dt1 &lt;- iris %&gt;% as.data.table dt1[, avg_sepal_length := mean(Sepal.Length)] dt1 In-place assignment brings significant speed benefits When an object is modified by using &lt;- to change some part of it, the assignment works by creating a whole new version of that object. The new version takes up a new space in memory, in addition to the previous version of the object. In-place assignment, on the other hand, is more memory efficient because it modifies the existing object in memory rather than creating a new one. The code below uses the tracemem() function to show the memory addresses of the object versions as assignment takes place. The long hexademical number displayed inside ‘&lt;&gt;’ is the memory address. dt1 &lt;- as.data.table(iris) tracemem(dt1) dt1$new_col &lt;- dt1$Sepal.Lenth + dt1$Sepal.Width tracemem(dt1) # Standard assignment created a new memory location dt2 &lt;- as.data.table(iris) tracemem(dt2) dt2[, new_col := Sepal.Length + Sepal.Width] tracemem(dt2) # In-place assignment did not. untracemem(dt1) untracemem(dt2) Be careful – this can change objects that you may not expect. Use copy() when in doubt. It’s easiest to demonstrate this with a simple example: dt1 &lt;- iris %&gt;% as.data.table dt2 &lt;- dt1 dt2[, Sepal.Length := NA] dt1 # dt1 has also been changed! In the example above, the assignment dt2 &lt;- dt1 did not take up any new space in memory (run tracemem() on both objects to see this). It did not need to, because it was just giving the object another name. This does not cause any issues when using standard assignment, because as soon as the dt2 object is modified, the modified version will be given a new memory address. However, because in-place assignment modifies in place, it will modify the object regardless of what other names it has. When in doubt, use copy() to make sure you’re creating a new object, if it could cause problems to modify an existing one. dt1 &lt;- iris %&gt;% as.data.table dt2 &lt;- copy(dt1) dt2 dt2[, Sepal.Length := NA] dt1 # dt1 has not been changed because copy() gave dt2 a new memory address. 5.3.3 Operations by groups of rows First, observe how operations work without any row grouping. As we saw in the in-place assignment examples, columns in a data table can be operated on after the comma in the indexing operator []. When the operations are not combined with assignment, they just return the result of the operations. dt1 &lt;- iris %&gt;% as.data.table dt1[1:5, Sepal.Length * Sepal.Width] This is true regardless of the length of the vector created by the operation: dt1 &lt;- iris %&gt;% as.data.table dt1[1:5, sum(Sepal.Length * Sepal.Width)] # Note that above, the row indexing is done first, so the result of the sum is coming # only from the first five rows of the data table. dt1[, sum(Sepal.Length * Sepal.Width)] # This is using all rows. The by argument for grouping. Data tables provide a simple way to perform such operations by groups of rows, the same way that GROUP BY works in SQL. For example, the following takes the mean sepal area for each species: dt1 &lt;- iris %&gt;% as.data.table dt1[, mean(Sepal.Length * Sepal.Width), by=Species] To name the column that contains the results, generate it as a named list. dt1 &lt;- iris %&gt;% as.data.table dt1[, .(avg_sepal_area = mean(Sepal.Length * Sepal.Width)), by=Species] This works with multiple different operations, as long as they are grouped by the same column/s. dt1 &lt;- iris %&gt;% as.data.table dt1[, .(avg_sepal_length = mean(Sepal.Length), avg_sepal_area = mean(Sepal.Length * Sepal.Width)), by=Species] Operations can be grouped by multiple columns, which makes the grouping more granular. Say we want take take the mean sepal length by species, but take separate means for observations with sepal width above and below the median. dt1 &lt;- iris %&gt;% as.data.table # Create a new column for above or below median. dt1[, above_med_sepal_width := Sepal.Length &gt; median(Sepal.Length)] # In the line above, the median() collapses the column to a single value, but then # comparing it against the Sepal.Length column using `&gt;` means the result is a vector # of same length as Sepal.Length. dt1[, .(num_obs = length(Sepal.Length), avg_sepal_area = mean(Sepal.Length * Sepal.Width)), by=.(Species, above_med_sepal_width)] With in-place assignment, similar to if there’s no grouping, the results are repeated to match the length of the existing columns. dt1 &lt;- iris %&gt;% as.data.table dt1[, avg_sepal_area := mean(Sepal.Length * Sepal.Width), by=Species] dt1 5.3.4 Handy data.table functions The data.table package also introduces many useful functions, and modifications of existing base R functions that are specifically designed for use on data tables. Some of the most useful of these include: melt(). Reshapes a data table from ‘wide’ to ‘long’. dcast(). Reshapes a data table from ‘long’ to ‘wide’ setkey(). Orders a data table by the specified variables and makes subsequent ‘grouped’ operaitons faster. merge(). Joins two data tables with different variables, based on specified common variables (similar to JOIN in SQL). rbind(). Short for ‘row bind’, joins two data tables with the same variables, by putting one underneath the other. fifelse(). Vectorised ‘if’ function – does operations to only selected elements of a vector, with selection based on a logical vector. There is plenty more great data.table functionality that hasn’t been covered here. When you want to do something you haven’t learnt, use the help resources list above as well as stack overflow. A feature that I commonly use is to use lapply() to apply a function to multiple columns simultaneously (because a data table treats itself as a type of list of columns), and use .SD and .SDcols to specify which columns to operate on. dt1 &lt;- iris %&gt;% as.data.table dt1[, lapply(.SD, function(x) x + 10), .SDcols=c(&#39;Sepal.Length&#39;, &#39;Sepal.Width&#39;)] # The .SD object tells data.table &#39;do this on a subset of columns&#39;, then the .SDcols # argument tells data.table which columns. If you leave out the .SDcols argument, it # does it on all columns (or tries to). # data.table has several other shorthands like .SD that add functionality and felxibility. 5.4 Combining data.table and magrittr The combination of data tables and pipes produces neat, concise and readable code. Each line modifies the data table, either within its index operators [], or by calling a function on the data table. When using the index operators, the line starts with .[, where the . represents the output from the previous line. # Consider our earlier assignment of two new columns: dt1 &lt;- iris %&gt;% as.data.table dt1 &lt;- dt1[, c(&#39;sepal_area&#39;, &#39;petal_area&#39;) := .(Sepal.Length * Sepal.Width, Petal.Length * Petal.Width)] ### The data.table and pipes way # Making more use of pipes we could do the following, which is one line longer, but # arguably much easier to read. dt1 &lt;- copy(iris) %&gt;% # Use &#39;copy()&#39; in the first line to avoid modifying iris. as.data.table %&gt;% .[, sepal_area := Sepal.Length * Sepal.Width] %&gt;% .[, petal_area := Petal.Length * Petal.Width] # We can also put functions in the process if we want: dt2 &lt;- copy(iris) %&gt;% as.data.table %&gt;% .[, sepal_area := Sepal.Length * Sepal.Width] %&gt;% .[, petal_area := Petal.Length * Petal.Width] %&gt;% # In the following line, &#39;.&#39; appears twice to denote the output from the previous line. .[, obs_num := 1:nrow(.)] %&gt;% melt(id.vars=c(&#39;obs_num&#39;, &#39;Species&#39;)) %&gt;% # Reshape to long # Say we want to cap all petal_area values at 15: .[variable == &#39;petal_area&#39; &amp; value &gt; 15, value := 15] # Careful - sometimes the &#39;.&#39; has different meanings in the same line, for example: dt1 &lt;- copy(iris) %&gt;% as.data.table %&gt;% .[, .(length_dataset = nrow(.))] # The second &#39;.&#39; above is shorthand for &#39;list()&#39;; the other two are used by %&gt;% to refer # to the output from the previous step. # The rule to use: whenever &#39;.&#39; is followed by &#39;(&#39;, data.table is using it as shorthand # for &#39;list()&#39;. ### &#39;Piping&#39; data tables without magrittr # Turning back to the two-column assignment example, another way in data table is to # chain operations by placing more index operators side by side: dt1 &lt;- iris %&gt;% as.data.table dt1 &lt;- dt1[, sepal_area := Sepal.Length * Sepal.Width ][, petal_area := Petal.Length * Petal.Width] # But it&#39;s arguably neater with pipes (and easier to add functions into the process) 5.5 Why data.table rather than dplyr here The main alternative to data.table is dplyr, which is the Tidyverse package for working with data frames. The dplyr syntax is again different from base R – but more so and in different ways compared to data.table – so people tend to pick either data.table or dplyr and mostly stick to it. (Although it’s OK to use dplyr and data.table together, and on occasions that makes sense to do.) Many just use what they were first shown. Some choose based on which syntax they find more intuitive. In my experience, detail-oriented people tend to prefer the data.table syntax, due to its flexibility, and big-picture people tend to prefer the dplyr syntax, because it is very neat for what it was built for. Some other advantages of each option: data.table: runs faster; no package dependencies (i.e. stable); concise and flexible syntax; closer to base R, so it’s good for modelling (base R is still best for linear algebra); good official help files. dplyr: syntax closer to English (i.e. more words, fewer symbols); function arguments and outputs have consistent formats; lots of online tutorials. Both packages are continually having new functionality added to them, and both have an abundance of useful information on Stack Overflow. There is a detailed discussion comparing the two options, with contributions by developers of both packages, in this stack overflow post: https://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly. For information on dplyr, see its webpage: https://dplyr.tidyverse.org/. The linked page mentions five key dplyr functions. The dplyr functions and their data.table equivalents are: mutate() is done by := (see section 5.3.2). select() is done by indexing column names (closer to base R; see section 5.3.1). filter() is done by row indexing in [], as in base R. summarise() is done with the by argument (see section 5.3.3). arrange() can be done with setkey(), setorder(), order(), etc. "],["graphs.html", "Chapter 6 Graphs 6.1 Base R or ggplot? 6.2 Base R graph examples 6.3 ggplot graph examples", " Chapter 6 Graphs This chapter provides working example code for several graph types, which you can copy and modify for your own use. The code assumes that you have data.table, magrittr and ggplot2 installed and loaded. # Load these for the examples below to work for you library(ggplot2) library(data.table) library(magrittr) 6.1 Base R or ggplot? Base R and the ggplot2 package both have great graphing functionality. (And many other packages exist for less common types types of visualisations.) You can stick to one, but both come in handy. This is one way to use them: Base R for quick and dirty graphs, when you just want to see what the data look like, and you don’t need to show it to anyone else. For example, base R’s plot() was used in the section 2.6.2 code. ggplot2 for professional-looking graphs that don’t have a high degree of customisation. Most graphs tend to fall in this category. Base R for highly customised graphs. ggplot2 can be particularly fiddly if you want to include something in your graph that it isn’t built for. These cases are getting rarer as the package is continually developed, but when you encounter one, it can be much easier to use base R than trying to wrangle ggplot2. 6.2 Base R graph examples # Single variable graph uses the order of the data for the x axis plot(iris$Petal.Width) plot(iris$Petal.Width, t=&#39;l&#39;) # Second arg means &#39;type&#39; = &#39;line&#39;. Default is points. # Some functions add features to an existing graph plot(iris$Petal.Width, ylim=c(0, 7)) # Specify the y-axis range. Also works for xlim. lines(iris$Petal.Length, col=&#39;blue&#39;) # Adds another variable. points() works similar. # Two-variable scatterplot plot(iris$Petal.Width, iris$Petal.Length) # Next example modifies a few features. Many other things can be modified. plot(iris$Petal.Width, iris$Petal.Length, col=&#39;red&#39;, pch=20, # specify the point type. Options are here: https://r-lang.com/pch-in-r/ main=&#39;Example scatter plot&#39;, ylab=&#39;Petal length&#39;, xlab=&#39;Petal width&#39;, xaxt=&#39;n&#39;) # Specify no ticks on x axis, so it can be manually added in axis(1, # Axis ticks for side &#39;1&#39; (i.e. x axis) at=c(0, 1.25, 2.5), # Where to put the ticks labels=c(0, 1.25, 2.5)) # What to write under the ticks (could also be text) legend(0.1, 6.5, # Coordinates for placing the legend legend=c(&#39;Iris observations&#39;, &#39;Nothing of this colour in graph&#39;), # Legend text pch=20, # Legend symbols (could specify e.g. line type (lty) instead) col=c(&#39;red&#39;, &#39;blue&#39;), # Legend symbol colours bty=&#39;n&#39;) # Remove box around legend # Other types of graphs. Features can be changed same as example above. hist(iris$Petal.Length, main=&#39;Histogram example&#39;) hist(iris$Petal.Length, 50, main=&#39;Histogram example with more buckets&#39;,) # 50 buckets barplot(iris$Petal.Length[1:30], main=&#39;Barplot example&#39;) # Barplot with multiple variables wants the variables as rows. Use &#39;t()&#39; to transpose. barplot(t(iris[1:30, c(&#39;Petal.Length&#39;, &#39;Petal.Width&#39;)])) boxplot(iris[, c(&#39;Petal.Length&#39;, &#39;Petal.Width&#39;)], main=&#39;Boxplot example&#39;) plot(density(iris$Petal.Width), main=&#39;Density function example&#39;) plot(ecdf(iris$Petal.Width), main=&#39;CDF example&#39;) # cumulative distribution function There are more examples here: https://statisticsglobe.com/graphics-in-r. 6.3 ggplot graph examples The ggplot functions require a bit more code, which can be a bit less intuitive (although nicely systematic), but they have a more presentable default layout. The graphs typically require the data to be in a data frame with ‘long’ format. In data.table, the ‘melt()’ function converts wide to long. ### Scatterplots in ggplot # Minimal working example. plotdata &lt;- copy(iris) ggplot(plotdata, aes(x=Petal.Length, y=Petal.Width)) + geom_point() # Different colours ggplot(plotdata, aes(x=Petal.Length, y=Petal.Width, colour=Species)) + geom_point() # Another way. This is useful if you want to combine plot types (e.g. point and line), # and you want to use different variables in each type. ggplot(plotdata) + geom_point(aes(x=Petal.Length, y=Petal.Width)) # To give an example that mixes two types, first format and combine a couple of the # in-built datasets. These datasets are of type &#39;time series&#39; (ts) which nobody really # uses. So first format them into a more usable format. &#39;time()&#39; extracts the time # periods from a ts object. sunspot_dt &lt;- data.table(year = as.numeric(time(sunspot.year)), # remove ts object types sunspots = as.numeric(sunspot.year)) nhtemp_dt &lt;- data.table(year = as.numeric(time(nhtemp)), temp = as.numeric(nhtemp)) plotdata &lt;- nhtemp_dt %&gt;% merge(sunspot_dt, all.x=TRUE, by=&#39;year&#39;) ggplot(plotdata) + geom_col(aes(x=year, y=temp)) + geom_line(aes(x=year, y=sunspots)) # Putting the line 2nd layers it &#39;above&#39; the bars. # Simple line chart with multiple series. ggplot requires this type of chart to be in # long format. melt() is the data.table function for converting to long plotdata2 &lt;- copy(plotdata) %&gt;% melt(id.vars=&#39;year&#39;, variable.name=&#39;var&#39;, value.name=&#39;val&#39;) ggplot(plotdata2, aes(x=year, y=val, group=var, colour=var)) + geom_line() # Similar chart but with more features. plotdata &lt;- copy(iris) ggplot(plotdata, aes(x=Petal.Length, y=Petal.Width, colour=Species)) + # Colour specifies the variable to set colour by geom_point() + # Add points to the graph (based on the aesthetics provided above) coord_fixed(ratio = 1) + # Force x and y axes to have the same scale scale_y_continuous(limits=c(0, 2.5)) + # y axis limits scale_x_continuous(limits=c(0, 7), # x axis limits breaks=c(1, 3, 5, 7), # Location of x ticks labels=c(&#39;one&#39;, &#39;three&#39;, &#39;five&#39;, &#39;seven&#39;)) + # x tick labels geom_hline(yintercept=0) + # Add horizontal line at zero geom_segment(x=0, y=0, xend=7, yend=7, colour=&#39;black&#39;, linetype=2) + # Manually add line annotate(&#39;text&#39;, x=1, y=1.8, label=&#39;Equality line&#39;, colour=&#39;black&#39;) + # Manually add text ggtitle(&#39;Iris data graph with lots of unnecessary features\\nIncluding a 2-line title&#39;) + labs(y=&#39;Width&#39;, # y axis label x=&#39;Length&#39;, # x axis label colour=&#39;Species column&#39;) + # legend label (use &#39;&#39; for blank) theme(legend.position=&#39;bottom&#39;) # Default is legend on right side; this moves it. "],["coming-soon.html", "Chapter 7 Coming soon 7.1 Workflow 7.2 Good habits 7.3 Better examples", " Chapter 7 Coming soon 7.1 Workflow Will cover: source() and other related functions. Size of user-defined functions R Markdown Git User-written packages Example of my workflow 7.2 Good habits Will cover: Reiteration of things mentioned Goal is simple and short code Speed up code by vectorising Modelling principles – parsimony, use of assumptions, etc. Testing - custom testing and unit testing 7.3 Better examples Examples using real data that use the code features discussed across all chapters. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
